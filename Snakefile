# Snakefile

"""
lncRNA Discovery Pipeline

This workflow starts by merging transcript assemblies generated by StringTie from multiple RNA-seq samples.
It then performs transcript filtering, annotation, and coding potential prediction using three complementary tools:
FEELnc, COME, and LncDC. The pipeline integrates their results to produce a high-confidence consensus set of lncRNA candidates.

Key steps include:
- Merging sample-specific StringTie GTF files into a unified transcriptome annotation
- Categorizing transcripts as known or novel using gffcompare
- Additional annotation of transcripts using bedtools
- Extracting novel lncRNAs and converting them to FASTA sequences using gffread
- Filtering transcripts by length (≥ 200 nt)
- Running coding potential predictors (FEELnc, COME, LncDC) on novel transcripts
- Building a consensus lncRNA list based on combined predictions
- Annotating genomic context and potential target genes using bedtools
- Comparing candidates against public lncRNA databases
- Filtering by expression level and performing differential expression analysis

This pipeline is designed for reproducible, scalable lncRNA discovery from total RNA-seq data, focusing on immune cell transcriptomes.

"""

# Define samples from raw data directory
samples = glob_wildcards("raw_sample/{sample}_1.fastq.gz").sample

# Reference genome and annotation paths
GENOME_FASTA = "human_reference/GRCh38.p14.genome.fa"
GTF = "human_reference/gencode.v48.chr_patch_hapl_scaff.annotation.gtf"
BED = "human_reference/gencode.v48.bed"

rule all:
    input:
        "results/lncrna_candidates/consensus_annotated_lncrnas.bed"

# --------------------------
# Create GTF Mergelist
# --------------------------
# This rule generates a text file listing all sample-specific StringTie GTFs.
# The list is used as input for StringTie --merge to create a unified transcriptome annotation.

rule make_mergelist:
    input:
        expand("results/hisat2/stringtie/{sample}.transcripts.gtf", sample=samples)
    output:
        "results/hisat2/stringtie/mergelist.txt"
    run:
        with open(output[0], "w") as out:
            for fn in input:
                out.write(fn + "\n")

# --------------------------
# Merge StringTie GTFs
# --------------------------
# Merges all sample GTFs into a single transcriptome annotation using StringTie --merge.

rule stringtie_merge:
    input:
        mergelist = "results/hisat2/stringtie/mergelist.txt",
        gtf = GTF
    output:
        merged = "results/hisat2/stringtie/merged_transcripts.gtf"
    singularity:
        "docker://quay.io/biocontainers/stringtie:3.0.0--h29c0135_0"
    shell:
        "stringtie --merge -G {input.gtf} -o {output.merged} {input.mergelist}"

# --------------------------
# Annotate with gffcompare
# --------------------------
# Compares the merged transcriptome annotation to the reference GTF,
# assigning class codes and categorizing transcripts as known or novel.

rule gffcompare:
    input:
        merged_gtf = "results/hisat2/stringtie/merged_transcripts.gtf",
        reference_gtf = GTF
    output:
        annotated_gtf = "results/gffcompare/gffcompare.annotated.gtf",
        tracking = "results/gffcompare/gffcompare.tracking",
        tmap = "results/hisat2/stringtie/gffcompare.merged_transcripts.gtf.tmap"
    singularity:
        "docker://quay.io/biocontainers/gffcompare:0.12.9--h9948957_0"
    shell:
        """
        mkdir -p results/gffcompare
        gffcompare -r {input.reference_gtf} -o results/gffcompare/gffcompare {input.merged_gtf}
        """

# --------------------------
# Extract novel transcripts from gffcompare output
# --------------------------
# Filters the gffcompare-annotated GTF to retain only novel transcripts
# based on class codes (e.g., "u" for intergenic, "x" for antisense).

rule extract_novel_transcripts:
    input:
        annotated_gtf = "results/gffcompare/gffcompare.annotated.gtf"
    output:
        novel_gtf = "results/lncrna/novel_transcripts.gtf"
    shell:
        """
        # DO NOT USE "c" FOR ANALYSIS; CHANGE!!
        awk '$3 == "transcript" && ($0 ~ /class_code "c"/ || $0 ~ /class_code "x"/ || $0 ~ /class_code "i"/)' \
        {input.annotated_gtf} > {output.novel_gtf}
        """

# --------------------------
# Convert gffcompare GTF to BED
# --------------------------
# Converts the annotated GTF from gffcompare to BED format for downstream bedtools annotation.

rule gffcompare_gtf_to_bed:
    input:
        annotated_gtf = "results/lncrna/novel_transcripts.gtf"
    output:
        bed = "results/gffcompare/gffcompare.annotated.bed"
    singularity:
        "docker://quay.io/biocontainers/gffread:0.12.7--h077b44d_6"
    shell:
        """
        gffread {input.annotated_gtf} -T -o- | awk '$3=="transcript"' | \
        awk '{{OFS="\\t"; print $1, $4-1, $5, $10, ".", $7}}' > {output.bed}
        """
# --------------------------
# Create BED file of known protein-coding gene exons
# --------------------------
# This rule extracts exons of protein-coding genes from the reference GTF
# and converts them to BED format for use in downstream annotation with bedtools.

rule make_known_genes_bed:
    input:
        gtf = GTF
    output:
        bed = BED
    singularity:
        "docker://quay.io/biocontainers/gffread:0.12.7--h077b44d_6"
    shell:
        # Extract exons of protein-coding genes and convert to BED
        """
        awk '$3 == "exon" && $0 ~ /gene_type "protein_coding"/' {input.gtf} > temp_protein_coding_exons.gtf
        gffread temp_protein_coding_exons.gtf -T -o- | \
        awk '$3=="exon"' | \
        awk '{{OFS="\\t"; print $1, $4-1, $5, $10, ".", $7}}' > {output.bed}
        rm temp_protein_coding_exons.gtf
        """

# --------------------------
# Annotate transcripts with bedtools
# --------------------------
# Uses bedtools intersect to find overlaps between transcripts (from gffcompare)
# and known genes or other genomic features, adding genomic context annotations.

rule annotate_with_bedtools:
    input:
        transcript_bed = "results/gffcompare/gffcompare.annotated.bed",
        genes_bed = BED
    output:
        annotated_bed = "results/lncrna/transcripts_annotated.bed"
    singularity:
        "docker://quay.io/biocontainers/bedtools:2.31.1--h13024bc_3"
    shell:
        """
        bedtools intersect -a {input.transcript_bed} -b {input.genes_bed} -wa -wb > {output.annotated_bed}
        """


# --------------------------
# Clean BED Fourth Column
# --------------------------
# Removes all double quotes (") and semicolons (;) from the fourth column of the BED file.
# This ensures compatibility with downstream tools like bedtools, which expect simple transcript names.
rule clean_bed_column:
    input:
        bed = "results/lncrna/transcripts_annotated.bed"
    output:
        cleaned_bed = "results/lncrna/transcripts_annotated.cleaned.bed"
    shell:
        """
        awk 'BEGIN{{FS=OFS="\\t"}} {{gsub(/"/, "", $4); gsub(/;/, "", $4); print}}' \
        {input.bed} > {output.cleaned_bed}
        """

# --------------------------
# Subset BED to First 6 Columns
# --------------------------
# Selects only the first 6 columns from the cleaned BED file.
# This produces a standard BED6 file suitable for sequence extraction with bedtools.
rule select_first_6_columns:
    input:
        cleaned_bed = "results/lncrna/transcripts_annotated.cleaned.bed"
    output:
        bed6 = "results/lncrna/transcripts_annotated.bed6"
    shell:
        """
        cut -f1-6 {input.cleaned_bed} > {output.bed6}
        """

# --------------------------
# Convert BED6 to FASTA
# --------------------------
# Extracts transcript sequences from the genome using the BED6 file.
# This step generates a FASTA file for downstream analysis or pipeline testing.
rule bed_to_fasta:
    input:
        bed = "results/lncrna/transcripts_annotated.bed6",
        genome = GENOME_FASTA
    output:
        fasta = "results/lncrna/transcripts_annotated.fa"
    singularity:
        "docker://quay.io/biocontainers/bedtools:2.31.1--h13024bc_3"
    shell:
        """
        bedtools getfasta -fi {input.genome} -bed {input.bed} -fo {output.fasta} -s -name
        """

# --------------------------
# Clean FASTA Headers
# --------------------------
# Removes appended coordinates from FASTA headers, leaving only the transcript ID.
# This ensures that extracted IDs will match those in the GTF file for downstream filtering.
rule clean_fasta_headers:
    input:
        fasta = "results/lncrna/transcripts_annotated.fa"
    output:
        cleaned_fasta = "results/lncrna/transcripts_annotated.cleaned.fa"
    shell:
        """
        sed -E 's/^>(ENST[0-9A-Za-z\\.]+)::.*$/>\\1/' {input.fasta} > {output.cleaned_fasta}
        """

# --------------------------
# Filter FASTA by Length (≥200 nt)
# --------------------------
# This rule filters the transcript FASTA file to retain only sequences
# that are at least 200 nucleotides long, as is standard for lncRNA discovery.
# This step ensures that only bona fide lncRNA candidates are used in downstream analyses.

rule filter_fasta_by_length:
    input:
        fasta = "results/lncrna/transcripts_annotated.cleaned.fa"
    output:
        filtered_fasta = "results/lncrna/filtered_transcripts.fa"
    shell:
        """
        awk 'BEGIN{{RS=">"; ORS=""}} length($2) >= 200 {{print ">"$0}}' {input.fasta} > {output.filtered_fasta}
        """

# --------------------------
# Predict lncRNAs with LncDC
# --------------------------
# This rule runs LncDC on the filtered FASTA file of novel transcripts (≥200 nt)
# to predict their coding potential. The output is a CSV file listing predicted lncRNAs.

rule lncdc:
    input:
        filtered_fa = "results/lncrna/filtered_transcripts.fa"
    output:
        lncRNAs = "results/lncrna_candidates/lncdc.output.csv"
    # LncDC container (custom)
    singularity:
        "docker://mariahlee/lncdc:1.3.6"
    shell:
        """
        mkdir -p results/lncrna_candidates && \
        python scripts/lncDC/LncDC-1.3.6/bin/lncDC.py -i {input.filtered_fa} -o {output.lncRNAs}
        """

# --------------------------
# Coding Potential Prediction with CPC2
# --------------------------
# Runs CPC2 on the filtered transcript FASTA file to classify each transcript as coding or non-coding.

rule cpc2:
    input:
        fasta = "/mnt/c/Users/leemc/Projects/encode_project/results/lncrna/filtered_transcripts.fa"
    output:
        result = "/mnt/c/Users/leemc/Projects/encode_project/results/lncrna_candidates/cpc2/cpc2_result.tsv"
    singularity:
        "docker://mariahlee/cpc2:1.0.1"
    shell:
        """
        mkdir -p results/lncrna_candidates/cpc2 && \
        cd /CPC2_standalone-1.0.1/ && \
        bin/CPC2.py -i {input.fasta} -o {output.result}
        """
# --------------------------
# Extract transcript IDs from filtered FASTA
# --------------------------
# This rule parses the filtered FASTA file of novel transcripts (≥200 nt)
# and extracts the transcript IDs from the FASTA headers. These IDs will be used
# to synchronize and filter other files (e.g., BED, GTF) so that all formats
# represent the same set of high-confidence lncRNA candidates.

rule extract_fasta_ids:
    input:
        fasta = "results/lncrna/filtered_transcripts.fa"
    output:
        ids = "results/lncrna/filtered_transcript_ids.txt"
    shell:
        "grep '^>' {input.fasta} | sed 's/^>//' > {output.ids}"

# --------------------------
# Filter GTF by transcript IDs
# --------------------------
# This rule filters the GTF file to retain only transcripts whose IDs are present
# in a provided list. The resulting GTF can be used as input for FEELnc and COME.
# Uses gffread's --ids option for efficient and robust filtering.

rule filter_gtf_by_ids:
    input:
        gtf = "results/lncrna/novel_transcripts.gtf",  # The GTF file to filter
        ids = "results/lncrna/filtered_transcript_ids.txt"  # List of transcript IDs to keep
    output:
        filtered_gtf = "results/lncrna/filtered_transcripts.gtf"
    singularity:
        "docker://quay.io/biocontainers/gffread:0.12.7--h077b44d_6"
    shell:
        """
        gffread {input.gtf} --ids {input.ids} -T -o {output.filtered_gtf}
        """

# --------------------------
# FEELnc: Filter candidate lncRNAs
# --------------------------
# Filters assembled/novel transcripts to remove those overlapping protein-coding genes,
# applies minimum length, and outputs candidate lncRNAs for coding potential analysis.

rule feelnc_filter:
    input:
        gtf = "results/lncrna/filtered_transcripts.gtf",
        annotation = GTF
    output:
        candidates = "results/feelnc/candidate_lncRNA.gtf"
    log:
        "results/feelnc/feelnc_filter.log"
    singularity:
        "docker://pasviber/feelnc:0.2.1"
    shell:
        """
        FEELnc_filter.pl -i {input.gtf} -a {input.annotation} -b transcript_biotype=protein_coding -s 200 > {output.candidates} 2> {log}
        """

# --------------------------
# FEELnc: Coding potential prediction
# --------------------------
# Predicts the coding potential of candidate lncRNAs using FEELnc_codpot.
# Requires the filtered candidate GTF and the reference genome FASTA.

rule feelnc_codpot:
    input:
        candidates = "results/feelnc/candidate_lncRNA.gtf",
        genome = GENOME_FASTA
    output:
        codpot = "results/feelnc/candidate_lncRNA_codpot.txt"
    log:
        "results/feelnc/feelnc_codpot.log"
    singularity:
        "docker://pasviber/feelnc:0.2.1"
    shell:
        """
        FEELnc_codpot.pl -i {input.candidates} -a {input.candidates} -g {input.genome} > {output.codpot} 2> {log}
        """

# --------------------------
# FEELnc: Classify lncRNAs by genomic context
# --------------------------
# Classifies lncRNAs by their genomic context relative to known genes (e.g., intergenic, antisense).
# Produces a tabular summary of lncRNA classes and a log file.

rule feelnc_classifier:
    input:
        lncRNA_gtf = "results/feelnc/candidate_lncRNA.gtf",
        annotation = GTF
    output:
        classes = "results/feelnc/candidate_lncRNA_classes.txt",
        log = "results/feelnc/candidate_lncRNA_feelncclassifier.log",
        feelnc_final = "results/lncrna_candidates/feelnc/candidate_lncRNA_classes.txt"
    singularity:
        "docker://pasviber/feelnc:0.2.1"
    shell:
        """
        mkdir -p results/lncrna_candidates/feelnc && \
        FEELnc_classifier.pl -i {input.lncRNA_gtf} -a {input.annotation} > {output.classes} 2> {output.log} \
        cp {output.classes} {output.feelnc_final}
        """

# --------------------------
# Find consensus lncRNAs across all predictors
# --------------------------
# This rule finds the intersection of transcript IDs predicted as lncRNAs by
# LncDC, COME, and FEELnc, and outputs a list of consensus lncRNA IDs.

rule consensus_lncrnas:
    input:
        lncdc = "results/lncrna_candidates/lncdc.output.csv",
        cpc2 = "results/lncrna_candidates/cpc2/cpc2_result.tsv.feat",
        feelnc = "results/lncrna_candidates/feelnc/candidate_lncRNA_classes.txt"
    output:
        ids = "results/lncrna_candidates/consensus_lncrna_ids.txt"
    script:
        "scripts/consensus/lncrna_consensus.py"

# --------------------------
# Filter annotated BED by consensus lncRNA IDs
# --------------------------
# This rule filters the annotated BED file to retain only transcripts whose IDs
# are present in the consensus lncRNA ID list. The transcript ID is assumed to be in column 4.
# The output is a fully annotated BED file of high-confidence novel lncRNAs.

rule filter_bed_by_consensus_ids:
    input:
        annotated_bed = "results/lncrna/transcripts_annotated.bed",
        consensus_ids = "results/lncrna_candidates/consensus_lncrna_ids.txt"
    output:
        filtered_bed = "results/lncrna_candidates/consensus_annotated_lncrnas.bed"
    shell:
        "grep -Fw -f {input.consensus_ids} {input.annotated_bed} > {output.filtered_bed}"
